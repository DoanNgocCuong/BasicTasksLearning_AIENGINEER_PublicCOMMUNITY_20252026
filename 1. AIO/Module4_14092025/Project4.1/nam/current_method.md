### TÃ³m Táº¯t Chi Tiáº¿t Quy TrÃ¬nh vÃ  Káº¿t Quáº£ Dá»± Ãn

TÃ i liá»‡u nÃ y ghi láº¡i quÃ¡ trÃ¬nh cáº£i tiáº¿n bÃ i toÃ¡n phÃ¢n loáº¡i chá»§ Ä‘á» bÃ i bÃ¡o ArXiv, chuyá»ƒn tá»« má»™t phÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n Ä‘Æ¡n giáº£n sang má»™t há»‡ thá»‘ng phÃ¢n cáº¥p Ä‘a nhÃ£n tinh vi hÆ¡n. Má»¥c tiÃªu lÃ  xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh khÃ´ng chá»‰ dá»± Ä‘oÃ¡n Ä‘Ãºng lÄ©nh vá»±c mÃ  cÃ²n cÃ³ kháº£ nÄƒng nháº­n diá»‡n tÃ­nh liÃªn ngÃ nh cá»§a khoa há»c.
#### 0. Code Ä‘ang dÃ¹ng
```python
# ===================================================================
# PHáº¦N 0: CÃC THÆ¯ VIá»†N Cáº¦N THIáº¾T
# ===================================================================
print("ğŸš€ Äang import cÃ¡c thÆ° viá»‡n...")
# ... (Pháº§n import giá»¯ nguyÃªn nhÆ° trÆ°á»›c) ...
import pandas as pd
import numpy as np
import ast
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    print("âš ï¸ ThÆ° viá»‡n sentence-transformers chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t. Äang tiáº¿n hÃ nh cÃ i Ä‘áº·t...")
    !pip install -U sentence-transformers
    from sentence_transformers import SentenceTransformer
    print("âœ… CÃ i Ä‘áº·t sentence-transformers thÃ nh cÃ´ng!")
from sklearn.multiclass import OneVsRestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import f1_score, jaccard_score, classification_report
import warnings
warnings.filterwarnings('ignore')
print("âœ… Import thÆ° viá»‡n hoÃ n táº¥t.")

# ===================================================================
# PHáº¦N 1: Táº¢I VÃ€ CHUáº¨N Bá»Š Dá»® LIá»†U
# ===================================================================
print("\nğŸš€ [BÆ°á»›c 1/5] Táº£i vÃ  chuáº©n bá»‹ dá»¯ liá»‡u...")

# --- Cáº¥u hÃ¬nh ---
# Äáº£m báº£o Ä‘Æ°á»ng dáº«n nÃ y CHÃNH XÃC
FILE_PATH = "/content/drive/MyDrive/data/arxiv_perfectly_balanced.csv"
SAMPLE_SIZE = None # Äáº·t lÃ  má»™t sá»‘ (vÃ­ dá»¥: 10000) Ä‘á»ƒ cháº¡y thá»­, hoáº·c None Ä‘á»ƒ cháº¡y toÃ n bá»™

df = None # Khá»Ÿi táº¡o df lÃ  None
try:
    df = pd.read_csv(FILE_PATH)
    print(f"âœ… Táº£i thÃ nh cÃ´ng file: '{FILE_PATH}' ({len(df):,} máº«u)")

    if SAMPLE_SIZE and SAMPLE_SIZE < len(df):
        print(f"   - Láº¥y máº«u thá»­ nghiá»‡m vá»›i {SAMPLE_SIZE:,} dÃ²ng.")
        df = df.sample(n=SAMPLE_SIZE, random_state=42).reset_index(drop=True)

except FileNotFoundError:
    print(f"âŒ Lá»–I NGHIÃŠM TRá»ŒNG: KhÃ´ng tÃ¬m tháº¥y file táº¡i '{FILE_PATH}'.")
    print("   - Vui lÃ²ng kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n vÃ  tÃªn file.")
    # Cháº¡y lá»‡nh ls Ä‘á»ƒ giÃºp debug
    !ls "/content/drive/MyDrive/AIO25/m04/data/"

# --- Chá»‰ cháº¡y pháº§n cÃ²n láº¡i náº¿u df Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng ---
if df is not None:
    # Chuyá»ƒn Ä‘á»•i cÃ¡c cá»™t nhÃ£n tá»« chuá»—i vá» list
    df['parent_labels'] = df['parent_labels'].apply(ast.literal_eval)
    df['child_labels'] = df['child_labels'].apply(ast.literal_eval)

    # --- Chuáº©n bá»‹ dá»¯ liá»‡u cho Táº§ng 1: Dá»± Ä‘oÃ¡n NhÃ£n Cha ---
    X = df['abstract'].astype(str)
    y = df['parent_labels']

    # MÃ£ hÃ³a nhÃ£n Ä‘a nhÃ£n thÃ nh ma tráº­n nhá»‹ phÃ¢n
    mlb = MultiLabelBinarizer()
    y_binarized = mlb.fit_transform(y)
    print(f"âœ… ÄÃ£ mÃ£ hÃ³a {len(mlb.classes_)} nhÃ£n cha thÃ nh ma tráº­n nhá»‹ phÃ¢n.")
    print(f"   - CÃ¡c lá»›p: {mlb.classes_}")

    # Chia dá»¯ liá»‡u train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_binarized, test_size=0.2, random_state=42
    )
    print(f"âœ… ÄÃ£ chia dá»¯ liá»‡u: {len(X_train):,} train, {len(X_test):,} test.")

    # GIáº¢I PHÃ“NG Bá»˜ NHá»š
    del df
    import gc
    gc.collect()
    print("   - ÄÃ£ giáº£i phÃ³ng bá»™ nhá»› cá»§a DataFrame gá»‘c.")

# ===================================================================
# PHáº¦N 2: MÃƒ HÃ“A VÄ‚N Báº¢N (FEATURE ENGINEERING) - ÄÃƒ Sá»¬A Lá»–I
# ===================================================================
print("\nğŸš€ [BÆ°á»›c 2/5] MÃ£ hÃ³a vÄƒn báº£n (BoW, TF-IDF, Embeddings)...")

# --- 2.1 Bag-of-Words (BoW) ---
print("\n--- 2.1 MÃ£ hÃ³a báº±ng Bag-of-Words ---")
bow_vectorizer = CountVectorizer(max_features=10000, stop_words='english')
X_train_bow = bow_vectorizer.fit_transform(X_train)
X_test_bow = bow_vectorizer.transform(X_test)
print(f"   - KÃ­ch thÆ°á»›c X_train_bow: {X_train_bow.shape}")

# --- 2.2 TF-IDF ---
print("\n--- 2.2 MÃ£ hÃ³a báº±ng TF-IDF ---")
tfidf_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)
print(f"   - KÃ­ch thÆ°á»›c X_train_tfidf: {X_train_tfidf.shape}")


# --- 2.3 Sentence Embeddings (Sá»¬ Dá»¤NG CLASS Má»šI ÄÃƒ Tá»I Æ¯U) ---
print("\n--- 2.3 MÃ£ hÃ³a báº±ng Sentence Embeddings ---")

class EmbeddingVectorizer:
    """MÃ£ hÃ³a vÄƒn báº£n thÃ nh vector embeddings sá»­ dá»¥ng SentenceTransformers."""
    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):
        self.model = SentenceTransformer(model_name)
        self.is_e5_model = 'e5' in model_name.lower()

    # Sá»­a Ä‘á»•i: Loáº¡i bá» tham sá»‘ precision khá»i Ä‘á»‹nh nghÄ©a hÃ m
    def transform(self, texts: pd.Series, batch_size: int = 64) -> np.ndarray:
        texts_list = texts.tolist()
        if self.is_e5_model:
            print(f"   - MÃ´ hÃ¬nh E5 Ä‘Æ°á»£c phÃ¡t hiá»‡n. Äang thÃªm tiá»n tá»‘ 'passage: '...")
            texts_to_encode = [f"passage: {text}" for text in texts_list]
        else:
            texts_to_encode = texts_list

        print(f"   - Báº¯t Ä‘áº§u mÃ£ hÃ³a {len(texts_to_encode):,} vÄƒn báº£n vá»›i mÃ´ hÃ¬nh '{self.model.tokenizer.name_or_path}'...")
        embeddings = self.model.encode(
            texts_to_encode,
            show_progress_bar=True,
            normalize_embeddings=True,
            batch_size=batch_size
            # KhÃ´ng truyá»n tham sá»‘ precision ná»¯a
        )
        return embeddings

# **Lá»°A CHá»ŒN MÃ” HÃŒNH EMBEDDING**
model_name = 'all-MiniLM-L6-v2' # Nhanh, hiá»‡u quáº£, 384 chiá»u

embedding_vectorizer = EmbeddingVectorizer(model_name=model_name)

# Sá»­a Ä‘á»•i: Loáº¡i bá» tham sá»‘ precision khi gá»i hÃ m
X_train_embeddings = embedding_vectorizer.transform(X_train, batch_size=128)
X_test_embeddings = embedding_vectorizer.transform(X_test, batch_size=128)

print("âœ… MÃ£ hÃ³a embeddings hoÃ n táº¥t.")
print(f"   - KÃ­ch thÆ°á»›c X_train_embeddings: {X_train_embeddings.shape}")

# ===================================================================
# PHáº¦N 3: Äá»ŠNH NGHÄ¨A CÃC MÃ” HÃŒNH (ÄÃƒ Tá»I Æ¯U HÃ“A)
# ===================================================================
print("\nğŸš€ [BÆ°á»›c 3/5] Äá»‹nh nghÄ©a cÃ¡c mÃ´ hÃ¬nh hiá»‡u nÄƒng cao...")

# CÃ¡c mÃ´ hÃ¬nh nÃ y nhanh vÃ  máº¡nh máº½
models_to_train = {
    'KNN': KNeighborsClassifier(n_jobs=-1),
    'DecisionTree': DecisionTreeClassifier(random_state=42),
    'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),
    'XGBoost': OneVsRestClassifier(
        XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', n_jobs=-1),
        n_jobs=-1
    ),
    'LightGBM': OneVsRestClassifier(
        LGBMClassifier(random_state=42, n_jobs=-1),
        n_jobs=-1
    ),
}

print(f"âœ… Sáºµn sÃ ng huáº¥n luyá»‡n {len(models_to_train)} mÃ´ hÃ¬nh hiá»‡u nÄƒng cao.")

# ===================================================================
# PHáº¦N 4: HUáº¤N LUYá»†N VÃ€ ÄÃNH GIÃ (ÄÃƒ Sá»¬A Lá»–I VÃ€ THÃŠM SO SÃNH)
# ===================================================================
print("\nğŸš€ [BÆ°á»›c 4/5] Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡...")

from sklearn.metrics import accuracy_score
from tqdm.auto import tqdm

datasets_for_training = {
    'BoW': (X_train_bow.astype(np.float32), X_test_bow.astype(np.float32)), # Ã‰P KIá»‚U á» ÄÃ‚Y
    'TF-IDF': (X_train_tfidf, X_test_tfidf),
    'Embeddings': (X_train_embeddings, X_test_embeddings)
}

results = []

# --- Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ tÃ­nh Accuracy so sÃ¡nh ---
# Láº¥y nhÃ£n Ä‘áº§u tiÃªn tá»« y_test Ä‘a nhÃ£n
y_test_single_label = np.array([np.where(row == 1)[0][0] if np.sum(row) > 0 else -1 for row in y_test])


total_runs = len(models_to_train) * len(datasets_for_training)
with tqdm(total=total_runs, desc="Tá»•ng tiáº¿n Ä‘á»™ huáº¥n luyá»‡n") as pbar:
    for model_name, model in models_to_train.items():
        for data_name, (X_train_data, X_test_data) in datasets_for_training.items():
            pbar.set_description(f"Huáº¥n luyá»‡n {model_name} vá»›i {data_name}")
            
            model.fit(X_train_data, y_train)
            y_pred = model.predict(X_test_data)
            
            # --- TÃNH TOÃN CÃC METRICS ---
            subset_accuracy = accuracy_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred, average='samples', zero_division=0)
            jaccard = jaccard_score(y_test, y_pred, average='samples', zero_division=0)

            # --- TÃNH ACCURACY Äá»‚ SO SÃNH ---
            # Chuyá»ƒn y_pred Ä‘a nhÃ£n thÃ nh Ä‘Æ¡n nhÃ£n (láº¥y nhÃ£n Ä‘áº§u tiÃªn)
            y_pred_single_label = np.array([np.where(row == 1)[0][0] if np.sum(row) > 0 else -1 for row in y_pred])
            # TÃ­nh accuracy trÃªn phiÃªn báº£n Ä‘Æ¡n nhÃ£n
            comparative_accuracy = accuracy_score(y_test_single_label, y_pred_single_label)
            
            results.append({
                'Model': model_name,
                'Encoding': data_name,
                'Comparative Accuracy': comparative_accuracy, # THÃŠM Cá»˜T NÃ€Y
                'Subset Accuracy': subset_accuracy,
                'F1 Score (Samples)': f1,
                'Jaccard Score (Samples)': jaccard
            })
            
            print(f"\n--- Káº¿t quáº£ cho: {model_name} vá»›i {data_name} ---")
            print(f"   -> Accuracy (So sÃ¡nh): {comparative_accuracy:.4f}") # THÃŠM DÃ’NG NÃ€Y
            print(f"   -> Subset Accuracy: {subset_accuracy:.4f}")
            print(f"   -> F1 Score: {f1:.4f}")
            print(f"   -> Jaccard Score: {jaccard:.4f}")
            
            pbar.update(1)


# ===================================================================
# PHáº¦N 5: Tá»”NG Káº¾T Káº¾T QUáº¢
# ===================================================================
print("\nğŸš€ [BÆ°á»›c 5/5] Tá»•ng káº¿t káº¿t quáº£...")
results_df = pd.DataFrame(results)
# Sáº¯p xáº¿p theo Comparative Accuracy Ä‘á»ƒ dá»… so sÃ¡nh nháº¥t
results_df = results_df.sort_values(by='Comparative Accuracy', ascending=False).reset_index(drop=True)
print("\n" + "="*120)
print(" " * 40 + "Báº¢NG Xáº¾P Háº NG Káº¾T QUáº¢ PHÃ‚N LOáº I NHÃƒN CHA")
print("="*120)
print(results_df.to_string())
print("="*120)

# In ra classification report chi tiáº¿t cho mÃ´ hÃ¬nh tá»‘t nháº¥t
if not results_df.empty:
    best_model_info = results_df.iloc[0]
    best_model_name = best_model_info['Model']
    best_encoding_name = best_model_info['Encoding']

    print(f"\nğŸ” PhÃ¢n tÃ­ch chi tiáº¿t cho mÃ´ hÃ¬nh tá»‘t nháº¥t: {best_model_name} vá»›i {best_encoding_name}")
    best_model = models_to_train[best_model_name]
    X_train_best, X_test_best = datasets_for_training[best_encoding_name]

    print("   - Äang huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh tá»‘t nháº¥t Ä‘á»ƒ táº¡o report chi tiáº¿t...")
    best_model.fit(X_train_best, y_train)
    y_pred_best = best_model.predict(X_test_best)

    report = classification_report(y_test, y_pred_best, target_names=mlb.classes_, zero_division=0)
    print(report)
else:
    print("âš ï¸ KhÃ´ng cÃ³ káº¿t quáº£ nÃ o Ä‘á»ƒ phÃ¢n tÃ­ch.")
```
#### 1. So SÃ¡nh CÃ¡ch Tiáº¿p Cáº­n: CÅ© vs. Má»›i

Äá»ƒ hiá»ƒu rÃµ nhá»¯ng cáº£i tiáº¿n, chÃºng ta cáº§n so sÃ¡nh hai phÆ°Æ¡ng phÃ¡p:

| TiÃªu chÃ­ | PhÆ°Æ¡ng PhÃ¡p CÅ© (Project Gá»‘c) | **PhÆ°Æ¡ng PhÃ¡p Má»›i (Cáº£i Tiáº¿n)** |
| :--- | :--- | :--- |
| **Pháº¡m vi dá»¯ liá»‡u** | Láº¥y 1,000 máº«u Ä‘Æ¡n giáº£n, **chá»‰ thuá»™c 5 lÄ©nh vá»±c** Ä‘Æ°á»£c chá»n trÆ°á»›c. | LÃ m viá»‡c trÃªn toÃ n bá»™ **2.3 triá»‡u bÃ i bÃ¡o** Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  táº¡o ra má»™t bá»™ dá»¯ liá»‡u con **30,000 máº«u** Ä‘áº¡i diá»‡n cho **17 lÄ©nh vá»±c chÃ­nh**. |
| **Xá»­ lÃ½ nhÃ£n** | Láº¥y nhÃ£n Ä‘áº§u tiÃªn, bá» qua cÃ¡c nhÃ£n phá»¥. Coi má»—i bÃ i bÃ¡o lÃ  **Ä‘Æ¡n nhÃ£n**. | PhÃ¢n tÃ­ch cáº¥u trÃºc `.` vÃ  `-` Ä‘á»ƒ tá»± Ä‘á»™ng xÃ¡c Ä‘á»‹nh **nhÃ£n Cha (lÄ©nh vá»±c lá»›n)** vÃ  **nhÃ£n Con (chá»§ Ä‘á» chi tiáº¿t)**. Cháº¥p nháº­n vÃ  xá»­ lÃ½ bÃ i toÃ¡n **Ä‘a nhÃ£n**. |
| **CÃ¢n báº±ng dá»¯ liá»‡u** | Láº¥y 200 máº«u cho má»—i trong 5 lá»›p (cÃ¢n báº±ng Ä‘Æ¡n giáº£n). | Ãp dá»¥ng má»™t chiáº¿n lÆ°á»£c láº¥y máº«u phá»©c táº¡p Ä‘á»ƒ **cÃ¢n báº±ng Ä‘á»“ng thá»i cáº£ vá» sá»‘ lÆ°á»£ng giá»¯a 17 lá»›p vÃ  cáº£ vá» tá»· lá»‡ 50/50 giá»¯a cÃ¡c bÃ i bÃ¡o Ä‘Æ¡n nhÃ£n vÃ  Ä‘a nhÃ£n**. |
| **Kiáº¿n trÃºc mÃ´ hÃ¬nh** | Má»™t mÃ´ hÃ¬nh duy nháº¥t, phÃ¢n loáº¡i 1 trong 5 lá»›p. | XÃ¢y dá»±ng ná»n táº£ng cho **kiáº¿n trÃºc 2 táº§ng**: Táº§ng 1 dá»± Ä‘oÃ¡n cÃ¡c nhÃ£n Cha, Táº§ng 2 (tÆ°Æ¡ng lai) sáº½ dá»± Ä‘oÃ¡n cÃ¡c nhÃ£n Con tÆ°Æ¡ng á»©ng. |
| **Äá»™ khÃ³ bÃ i toÃ¡n** | **Tháº¥p:** PhÃ¢n loáº¡i Ä‘Æ¡n nhÃ£n, 5 lá»›p. | **Ráº¥t cao:** PhÃ¢n loáº¡i Ä‘a nhÃ£n, 17 lá»›p, yÃªu cáº§u dá»± Ä‘oÃ¡n Ä‘Ãºng má»™t táº­p há»£p cÃ¡c nhÃ£n. |

Vá» cÆ¡ báº£n, chÃºng ta Ä‘Ã£ chuyá»ƒn tá»« má»™t bÃ i toÃ¡n "Ä‘á»“ chÆ¡i" sang má»™t bÃ i toÃ¡n gáº§n vá»›i thá»±c táº¿ hÆ¡n ráº¥t nhiá»u.

---

#### 2. Quy TrÃ¬nh LÃ m Viá»‡c Chi Tiáº¿t

##### Giai Ä‘oáº¡n 1: Táº¡o Cáº¥u TrÃºc NhÃ£n Cha-Con

ChÃºng tÃ´i Ä‘Ã£ xÃ¢y dá»±ng má»™t quy trÃ¬nh tá»± Ä‘á»™ng Ä‘á»ƒ phÃ¢n cáº¥p hÆ¡n 2.3 triá»‡u bÃ i bÃ¡o:
1.  **Táº¡o á»¨ng Cá»­ ViÃªn:** QuÃ©t qua 3.8 triá»‡u lÆ°á»£t gÃ¡n nhÃ£n, trÃ­ch xuáº¥t pháº§n Ä‘áº§u cá»§a má»—i nhÃ£n (vÃ­ dá»¥ `math.CO` -> `math`) lÃ m "á»©ng cá»­ viÃªn" nhÃ£n cha.
2.  **Lá»±a Chá»n Dá»±a TrÃªn Dá»¯ Liá»‡u:** Äáº·t ra ngÆ°á»¡ng khÃ¡ch quan: chá»‰ nhá»¯ng á»©ng cá»­ viÃªn chiáº¿m hÆ¡n 0.1% "thá»‹ pháº§n" trong tá»•ng sá»‘ lÆ°á»£t gÃ¡n nhÃ£n má»›i Ä‘Æ°á»£c cÃ´ng nháº­n lÃ  NhÃ£n Cha. QuÃ¡ trÃ¬nh nÃ y Ä‘Ã£ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c **17 lÄ©nh vá»±c lá»›n**.
3.  **Táº¡o Cá»™t Má»›i:** Bá»• sung hai cá»™t `parent_labels` vÃ  `child_labels` vÃ o dataset gá»‘c.

##### Giai Ä‘oáº¡n 2: Táº¡o Dataset Con CÃ¢n Báº±ng Tá»‘i Æ¯u

Tá»« 2.3 triá»‡u dÃ²ng, chÃºng tÃ´i Ä‘Ã£ táº¡o ra má»™t bá»™ dá»¯ liá»‡u 30,000 máº«u (`arxiv_perfectly_balanced.csv`) vá»›i cÃ¡c Ä‘áº·c Ä‘iá»ƒm sau:
*   **CÃ¢n báº±ng Cáº¥u trÃºc:** CÃ³ chÃ­nh xÃ¡c **14,994 (50.0%)** bÃ i bÃ¡o Ä‘Æ¡n nhÃ£n vÃ  **15,000 (50.0%)** bÃ i bÃ¡o Ä‘a nhÃ£n.
*   **CÃ¢n báº±ng Lá»›p:** Sá»± chÃªnh lá»‡ch sá»‘ lÆ°á»£ng máº«u giá»¯a 17 lá»›p cha Ä‘Ã£ Ä‘Æ°á»£c giáº£m thiá»ƒu Ä‘Ã¡ng ká»ƒ, giÃºp mÃ´ hÃ¬nh khÃ´ng bá»‹ thiÃªn vá»‹.

##### Giai Ä‘oáº¡n 3: Huáº¥n Luyá»‡n vÃ  ÄÃ¡nh GiÃ¡ MÃ´ HÃ¬nh Táº§ng 1

ChÃºng tÃ´i Ä‘Ã£ xÃ¢y dá»±ng **Táº§ng 1** cá»§a há»‡ thá»‘ng, cÃ³ nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n cÃ¡c nhÃ£n cha tá»« abstract.
1.  **MÃ£ hÃ³a VÄƒn báº£n:** Dá»¯ liá»‡u abstract Ä‘Æ°á»£c mÃ£ hÃ³a báº±ng 3 phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ so sÃ¡nh: `Bag-of-Words (BoW)`, `TF-IDF`, vÃ  `Sentence Embeddings (all-MiniLM-L6-v2)`.
2.  **Huáº¥n luyá»‡n:** 5 mÃ´ hÃ¬nh Machine Learning hiá»‡u nÄƒng cao (`KNN`, `DecisionTree`, `RandomForest`, `XGBoost`, `LightGBM`) Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n. Do tÃ­nh cháº¥t Ä‘a nhÃ£n, cÃ¡c mÃ´ hÃ¬nh boosting Ä‘Æ°á»£c bá»c trong `OneVsRestClassifier`.
3.  **ÄÃ¡nh giÃ¡:** ChÃºng tÃ´i sá»­ dá»¥ng nhiá»u Ä‘á»™ Ä‘o, bao gá»“m `Subset Accuracy` (Ä‘á»™ chÃ­nh xÃ¡c kháº¯t khe, yÃªu cáº§u Ä‘oÃ¡n Ä‘Ãºng toÃ n bá»™ táº­p há»£p nhÃ£n) vÃ  `Comparative Accuracy` (Ä‘á»ƒ so sÃ¡nh tÆ°Æ¡ng Ä‘á»‘i vá»›i cÃ¡ch lÃ m cÅ©).

---

#### 3. Káº¿t Quáº£ Chi Tiáº¿t vÃ  Diá»…n Giáº£i

ToÃ n bá»™ quÃ¡ trÃ¬nh huáº¥n luyá»‡n 5 mÃ´ hÃ¬nh trÃªn 3 loáº¡i dá»¯ liá»‡u (tá»•ng cá»™ng 15 láº§n cháº¡y) máº¥t khoáº£ng **1 giá» 7 phÃºt** trÃªn Google Colab.

**Báº£ng xáº¿p háº¡ng káº¿t quáº£:**
```
           Model    Encoding  Comparative Accuracy  Subset Accuracy  F1 Score (Samples)  Jaccard Score (Samples)
0            KNN  Embeddings                0.5814           0.4059              0.6782                   0.6083
1        XGBoost  Embeddings                0.4984           0.3296              0.5949                   0.5272
2       LightGBM         BoW                0.4674           0.3177              0.5727                   0.5077
...          ...         ...                   ...              ...                 ...                      ...
```

**PhÃ¢n tÃ­ch káº¿t quáº£:**

1.  **Sá»± Káº¿t Há»£p Tá»‘t Nháº¥t:** **KNN** káº¿t há»£p vá»›i **Sentence Embeddings** cho káº¿t quáº£ vÆ°á»£t trá»™i trÃªn má»i chá»‰ sá»‘. Äiá»u nÃ y cho tháº¥y `Embeddings` Ä‘Ã£ táº¡o ra má»™t khÃ´ng gian vector giÃ u ngá»¯ nghÄ©a, vÃ  `KNN` (thuáº­t toÃ¡n dá»±a trÃªn khoáº£ng cÃ¡ch) Ä‘Ã£ táº­n dá»¥ng ráº¥t tá»‘t khÃ´ng gian Ä‘Ã³ Ä‘á»ƒ tÃ¬m ra cÃ¡c bÃ i bÃ¡o tÆ°Æ¡ng tá»±.

2.  **So SÃ¡nh Vá»›i CÃ¡ch LÃ m CÅ©:**
    *   `Comparative Accuracy` cao nháº¥t Ä‘áº¡t **58.14%**. Con sá»‘ nÃ y cÃ³ váº» tháº¥p hÆ¡n so vá»›i `accuracy` (~88%) cá»§a project cÅ©, nhÆ°ng Ä‘Ã¢y lÃ  má»™t káº¿t quáº£ **ráº¥t tá»‘t**.
    *   **LÃ½ do:** MÃ´ hÃ¬nh má»›i Ä‘ang giáº£i quyáº¿t má»™t bÃ i toÃ¡n khÃ³ hÆ¡n ráº¥t nhiá»u (17 lá»›p Ä‘a nhÃ£n vs. 5 lá»›p Ä‘Æ¡n nhÃ£n). Tá»· lá»‡ Ä‘oÃ¡n mÃ² chá»‰ lÃ  ~5.8%, mÃ´ hÃ¬nh cá»§a chÃºng ta lÃ m tá»‘t hÆ¡n gáº¥p 10 láº§n. Viá»‡c so sÃ¡nh trá»±c tiáº¿p lÃ  kháº­p khiá»…ng.

3.  **Hiá»‡u Suáº¥t Thá»±c Táº¿:**
    *   `Subset Accuracy` Ä‘áº¡t **40.59%**, nghÄ©a lÃ  mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n Ä‘Ãºng hoÃ n toÃ n má»™t táº­p há»£p cÃ¡c nhÃ£n (ká»ƒ cáº£ cÃ¡c nhÃ£n phá»©c táº¡p nhÆ° `['cs', 'math']`) trong hÆ¡n 40% trÆ°á»ng há»£p. ÄÃ¢y lÃ  má»™t con sá»‘ ráº¥t áº¥n tÆ°á»£ng.
    *   `F1 Score` vÃ  `Jaccard Score` Ä‘á»u cao (láº§n lÆ°á»£t lÃ  **67.8%** vÃ  **60.8%**), cho tháº¥y mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Ãºng pháº§n lá»›n cÃ¡c nhÃ£n cho má»—i bÃ i bÃ¡o, chá»©ng tá» kháº£ nÄƒng nháº­n diá»‡n liÃªn ngÃ nh ráº¥t tá»‘t.

**Káº¿t luáº­n:**
Quy trÃ¬nh tiá»n xá»­ lÃ½ vÃ  táº¡o dataset cÃ¢n báº±ng Ä‘Ã£ thÃ nh cÃ´ng. ChÃºng ta Ä‘Ã£ xÃ¢y dá»±ng Ä‘Æ°á»£c má»™t mÃ´ hÃ¬nh Táº§ng 1 máº¡nh máº½, cÃ³ kháº£ nÄƒng phÃ¢n loáº¡i Ä‘a nhÃ£n hiá»‡u quáº£, vÆ°á»£t xa kháº£ nÄƒng cá»§a phÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n Ä‘Æ¡n giáº£n ban Ä‘áº§u. Ná»n táº£ng nÃ y Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ tiáº¿p tá»¥c xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh Táº§ng 2 nháº±m phÃ¢n loáº¡i chi tiáº¿t cÃ¡c nhÃ£n con.

### TÃ³m Táº¯t Chi Tiáº¿t Quy TrÃ¬nh vÃ  Káº¿t Quáº£ Dá»± Ãn (XÃ¢y dá»±ng Ä‘áº§y Ä‘á»§ 2 táº§ng)

#### 1. XÃ¢y Dá»±ng vÃ  Chuáº©n Bá»‹ Dá»¯ Liá»‡u

Quy trÃ¬nh báº¯t Ä‘áº§u tá»« bá»™ dá»¯ liá»‡u gá»‘c hÆ¡n 2.2 triá»‡u bÃ i bÃ¡o, vá»‘n ráº¥t lá»›n vÃ  máº¥t cÃ¢n báº±ng. ChÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau Ä‘á»ƒ táº¡o ra má»™t táº­p dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao cho viá»‡c huáº¥n luyá»‡n:

1.  **PhÃ¢n Cáº¥p NhÃ£n (Cha-Con):**
    *   **PhÆ°Æ¡ng phÃ¡p:** ChÃºng tÃ´i Ä‘Ã£ phÃ¡t triá»ƒn má»™t quy trÃ¬nh tá»± Ä‘á»™ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c lÄ©nh vá»±c khoa há»c lá»›n (NhÃ£n Cha). Báº±ng cÃ¡ch quÃ©t qua 3.8 triá»‡u lÆ°á»£t gÃ¡n nhÃ£n, chÃºng tÃ´i trÃ­ch xuáº¥t cÃ¡c tiá»n tá»‘ (prefix) trÆ°á»›c dáº¥u `.` hoáº·c `-` (vÃ­ dá»¥: `math.CO` -> `math`).
    *   **Lá»±a chá»n:** Chá»‰ nhá»¯ng tiá»n tá»‘ chiáº¿m hÆ¡n 0.1% "thá»‹ pháº§n" trong tá»•ng sá»‘ cÃ¡c chá»§ Ä‘á» má»›i Ä‘Æ°á»£c cÃ´ng nháº­n lÃ  NhÃ£n Cha. QuÃ¡ trÃ¬nh nÃ y Ä‘Ã£ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c **17 NhÃ£n Cha** chÃ­nh, táº¡o ra má»™t cáº¥u trÃºc phÃ¢n cáº¥p cÃ³ Ã½ nghÄ©a.

2.  **Táº¡o Dataset Con CÃ¢n Báº±ng (30,000 máº«u):**
    *   **Má»¥c tiÃªu:** Táº¡o ra má»™t bá»™ dá»¯ liá»‡u nhá» hÆ¡n, dá»… quáº£n lÃ½ vÃ  **Ã­t thiÃªn vá»‹** nháº¥t cÃ³ thá»ƒ.
    *   **Chiáº¿n lÆ°á»£c:** ChÃºng tÃ´i Ä‘Ã£ Ã¡p dá»¥ng má»™t phÆ°Æ¡ng phÃ¡p láº¥y máº«u hai chiá»u phá»©c táº¡p Ä‘á»ƒ Ä‘áº£m báº£o bá»™ dá»¯ liá»‡u 30,000 máº«u cuá»‘i cÃ¹ng (`arxiv_perfectly_balanced.csv`) Ä‘áº¡t Ä‘Æ°á»£c hai má»¥c tiÃªu cÃ¢n báº±ng quan trá»ng:
        *   **CÃ¢n báº±ng Cáº¥u trÃºc:** Tá»· lá»‡ bÃ i bÃ¡o **Ä‘Æ¡n nhÃ£n (50.0%)** vÃ  **Ä‘a nhÃ£n (50.0%)** Ä‘Æ°á»£c giá»¯ á»Ÿ má»©c cÃ¢n báº±ng hoÃ n háº£o.
        *   **CÃ¢n báº±ng Lá»›p:** Sá»± chÃªnh lá»‡ch vá» sá»‘ lÆ°á»£ng máº«u giá»¯a 17 lá»›p cha Ä‘Æ°á»£c giáº£m thiá»ƒu Ä‘Ã¡ng ká»ƒ, giÃºp mÃ´ hÃ¬nh há»c má»™t cÃ¡ch cÃ´ng báº±ng hÆ¡n.

#### 2. Kiáº¿n TrÃºc MÃ´ HÃ¬nh PhÃ¢n Cáº¥p Hai Táº§ng

ChÃºng tÃ´i Ä‘Ã£ xÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n má»™t há»‡ thá»‘ng gá»“m hai táº§ng:

*   **Táº§ng 1 (Dá»± Ä‘oÃ¡n NhÃ£n Cha):**
    *   **Nhiá»‡m vá»¥:** Nháº­n má»™t `abstract` vÃ  dá»± Ä‘oÃ¡n má»™t hoáº·c nhiá»u trong sá»‘ 17 NhÃ£n Cha.
    *   **CÃ´ng nghá»‡:** ChÃºng tÃ´i sá»­ dá»¥ng mÃ´ hÃ¬nh `LightGBM` (bá»c trong `OneVsRestClassifier` Ä‘á»ƒ xá»­ lÃ½ Ä‘a nhÃ£n) vÃ  mÃ£ hÃ³a vÄƒn báº£n báº±ng `Sentence Embeddings` (mÃ´ hÃ¬nh `E5-base`) Ä‘á»ƒ táº¡o ra cÃ¡c vector ngá»¯ nghÄ©a cháº¥t lÆ°á»£ng cao.

*   **Táº§ng 2 (Dá»± Ä‘oÃ¡n NhÃ£n Con):**
    *   **Nhiá»‡m vá»¥:** Vá»›i má»—i NhÃ£n Cha Ä‘Æ°á»£c dá»± Ä‘oÃ¡n tá»« Táº§ng 1, má»™t mÃ´ hÃ¬nh con chuyÃªn biá»‡t sáº½ Ä‘Æ°á»£c kÃ­ch hoáº¡t Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡c NhÃ£n Con chi tiáº¿t.
    *   **CÃ´ng nghá»‡:** ChÃºng tÃ´i Ä‘Ã£ huáº¥n luyá»‡n **15 mÃ´ hÃ¬nh `LightGBM` riÃªng biá»‡t**, má»—i mÃ´ hÃ¬nh lÃ  má»™t "chuyÃªn gia" cho má»™t lÄ©nh vá»±c lá»›n (vÃ­ dá»¥: má»™t mÃ´ hÃ¬nh cho `math`, má»™t cho `cs`, v.v.).

#### 3. Káº¿t Quáº£ ÄÃ¡nh GiÃ¡ Hiá»‡u Suáº¥t

Sau khi huáº¥n luyá»‡n, toÃ n bá»™ há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn má»™t táº­p test gá»“m 5,999 bÃ i bÃ¡o.

**Káº¿t quáº£ Ä‘á»‹nh lÆ°á»£ng:**

*   **Hiá»‡u suáº¥t Táº§ng 1 (NhÃ£n Cha):**
    *   `Subset Accuracy`: **0.2275** (ÄoÃ¡n Ä‘Ãºng hoÃ n toÃ n táº­p há»£p nhÃ£n cha trong 22.7% trÆ°á»ng há»£p).
    *   `F1 Score (Samples)`: **0.4880** (Trung bÃ¬nh, mÃ´ hÃ¬nh Ä‘oÃ¡n Ä‘Ãºng khoáº£ng 49% cÃ¡c nhÃ£n cha cho má»—i bÃ i bÃ¡o).

*   **Hiá»‡u suáº¥t ToÃ n Há»‡ Thá»‘ng (NhÃ£n Con Cuá»‘i CÃ¹ng):**
    *   `F1 Score (Samples)`: **0.2572**
    *   `Jaccard Score`: **0.2157**

**Diá»…n giáº£i káº¿t quáº£ vÃ  PhÃ¢n tÃ­ch táº¡i sao hiá»‡u suáº¥t cÃ²n tháº¥p:**

Káº¿t quáº£ F1-score cuá»‘i cÃ¹ng lÃ  **25.7%** cho tháº¥y Ä‘Ã¢y lÃ  má»™t baseline ban Ä‘áº§u vÃ  cÃ²n nhiá»u khÃ´ng gian Ä‘á»ƒ cáº£i thiá»‡n. NguyÃªn nhÃ¢n chÃ­nh cá»§a hiá»‡u suáº¥t cÃ²n khiÃªm tá»‘n nÃ y Ä‘áº¿n tá»« sá»± cá»™ng hÆ°á»Ÿng cá»§a nhiá»u yáº¿u tá»‘:

1.  **Lá»—i Khuáº¿ch Äáº¡i tá»« Táº§ng 1:** Táº§ng 1 lÃ  "cá»­a ngÃµ" cá»§a há»‡ thá»‘ng. Vá»›i F1-score chá»‰ 49%, nÃ³ thÆ°á»ng xuyÃªn dá»± Ä‘oÃ¡n sai hoáº·c bá» sÃ³t cÃ¡c nhÃ£n cha. **Náº¿u Táº§ng 1 bá» sÃ³t má»™t nhÃ£n cha, Táº§ng 2 sáº½ khÃ´ng bao giá» cÃ³ cÆ¡ há»™i Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡c nhÃ£n con tÆ°Æ¡ng á»©ng, gÃ¢y ra lá»—i dÃ¢y chuyá»n.** ÄÃ¢y lÃ  Ä‘iá»ƒm yáº¿u lá»›n nháº¥t cá»§a há»‡ thá»‘ng hiá»‡n táº¡i.

2.  **Äá»™ KhÃ³ Cá»‘ Há»¯u cá»§a BÃ i ToÃ¡n:** Viá»‡c phÃ¢n loáº¡i chi tiáº¿t hÃ ng trÄƒm nhÃ£n con khÃ¡c nhau, Ä‘áº·c biá»‡t lÃ  trong cÃ¡c lÄ©nh vá»±c cÃ³ sá»± chá»“ng chÃ©o lá»›n vá» ngÃ´n ngá»¯ (vÃ­ dá»¥: `hep-th` vÃ  `math-ph`), lÃ  má»™t nhiá»‡m vá»¥ cá»±c ká»³ khÃ³ khÄƒn.

3.  **Hiá»‡u suáº¥t cá»§a cÃ¡c MÃ´ hÃ¬nh Con (Táº§ng 2):** Má»—i mÃ´ hÃ¬nh con Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t táº­p dá»¯ liá»‡u nhá» hÆ¡n vÃ  cÃ³ thá»ƒ chÆ°a Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a. Má»™t sá»‘ mÃ´ hÃ¬nh con cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng ráº¥t kÃ©m, kÃ©o hiá»‡u suáº¥t chung Ä‘i xuá»‘ng.

#### 4. PhÃ¢n TÃ­ch VÃ­ Dá»¥ Dá»± ÄoÃ¡n Thá»±c Táº¿

Äá»ƒ hiá»ƒu rÃµ hÆ¡n vá» hÃ nh vi cá»§a mÃ´ hÃ¬nh, hÃ£y xem xÃ©t má»™t vÃ i vÃ­ dá»¥ tá»« táº­p test:

*   **VÃ­ dá»¥ 1 (ThÃ nh cÃ´ng má»™t pháº§n, tháº¥t báº¡i á»Ÿ Táº§ng 2):**
    *   **Abstract:** Vá» "adaptive quantum circuits", "symmetry-breaking order", "gapless, local Hamiltonian".
    *   **NhÃ£n tháº­t (Con):** `['cond-mat.stat-mech', 'quant-ph']`
    *   **Dá»± Ä‘oÃ¡n Táº§ng 1:** `['cond-mat', 'quant']` -> **ÄÃšNG HOÃ€N TOÃ€N!**
    *   **Dá»± Ä‘oÃ¡n Táº§ng 2:** `[]` (trá»‘ng) -> **SAI!**
    *   **PhÃ¢n tÃ­ch:** Táº§ng 1 Ä‘Ã£ hoáº¡t Ä‘á»™ng xuáº¥t sáº¯c khi nháº­n diá»‡n Ä‘Ãºng cáº£ hai lÄ©nh vá»±c. Tuy nhiÃªn, cÃ¡c mÃ´ hÃ¬nh con cá»§a `cond-mat` vÃ  `quant` Ä‘Ã£ khÃ´ng Ä‘á»§ máº¡nh Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c chá»§ Ä‘á» chi tiáº¿t.

*   **VÃ­ dá»¥ 2 (Tháº¥t báº¡i á»Ÿ Táº§ng 1 - Bá» sÃ³t):**
    *   **Abstract:** Vá» "cellular networks", "full-duplex", "beamforming", "multi-cell network capacity".
    *   **NhÃ£n tháº­t (Cha):** `['cs', 'eess', 'math']`
    *   **Dá»± Ä‘oÃ¡n Táº§ng 1:** `['eess']` -> **SAI (thiáº¿u)**. MÃ´ hÃ¬nh chá»‰ nháº­n ra Ä‘Æ°á»£c khÃ­a cáº¡nh Ká»¹ thuáº­t Äiá»‡n (`eess`) mÃ  bá» qua hoÃ n toÃ n khÃ­a cáº¡nh Khoa há»c MÃ¡y tÃ­nh (`cs`) vÃ  ToÃ¡n há»c (`math`).
    *   **PhÃ¢n tÃ­ch:** ÄÃ¢y lÃ  lá»—i phá»• biáº¿n nháº¥t. Do Táº§ng 1 bá» sÃ³t `cs` vÃ  `math`, cÃ¡c mÃ´ hÃ¬nh con tÆ°Æ¡ng á»©ng khÃ´ng Ä‘Æ°á»£c kÃ­ch hoáº¡t, dáº«n Ä‘áº¿n viá»‡c cÃ¡c nhÃ£n con `cs.IT`, `cs.NI`, `math.IT` cÅ©ng bá»‹ bá» lá»¡.

*   **VÃ­ dá»¥ 3 (Tháº¥t báº¡i á»Ÿ Táº§ng 1 - Nháº§m láº«n):**
    *   **Abstract:** Vá» "copositivity", "scalar potentials", "Higgs boson", "two Higgs doublet model".
    *   **NhÃ£n tháº­t (Cha):** `['hep']`
    *   **Dá»± Ä‘oÃ¡n Táº§ng 1:** `['gr', 'hep', 'patt-sol']` -> **SAI (thá»«a)**. MÃ´ hÃ¬nh Ä‘Ã£ Ä‘oÃ¡n Ä‘Ãºng `hep` nhÆ°ng láº¡i "áº£o giÃ¡c" ra cáº£ Háº¥p dáº«n LÆ°á»£ng tá»­ (`gr`) vÃ  má»™t nhÃ£n khÃ´ng liÃªn quan.
    *   **PhÃ¢n tÃ­ch:** MÃ´ hÃ¬nh váº«n cÃ²n nháº§m láº«n giá»¯a cÃ¡c lÄ©nh vá»±c cÃ³ tá»« vá»±ng tÆ°Æ¡ng tá»± nhau.

**Káº¿t luáº­n chung:**
Há»‡ thá»‘ng phÃ¢n cáº¥p hai táº§ng hiá»‡n táº¡i Ä‘Ã£ Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ nh cÃ´ng vÃ  cho tháº¥y tiá»m nÄƒng trong viá»‡c xá»­ lÃ½ bÃ i toÃ¡n phá»©c táº¡p. Tuy nhiÃªn, hiá»‡u suáº¥t hiá»‡n táº¡i cÃ²n háº¡n cháº¿, chá»§ yáº¿u do Ä‘á»™ chÃ­nh xÃ¡c chÆ°a cao cá»§a mÃ´ hÃ¬nh Táº§ng 1. CÃ¡c bÆ°á»›c cáº£i thiá»‡n trong tÆ°Æ¡ng lai nÃªn táº­p trung vÃ o viá»‡c **tá»‘i Æ°u hÃ³a máº¡nh máº½ mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n nhÃ£n cha** Ä‘á»ƒ táº¡o ra má»™t ná»n táº£ng vá»¯ng cháº¯c hÆ¡n cho Táº§ng 2 hoáº¡t Ä‘á»™ng.