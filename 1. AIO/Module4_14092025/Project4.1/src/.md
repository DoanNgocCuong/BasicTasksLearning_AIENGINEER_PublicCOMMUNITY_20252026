Chốt lại: 

Cách làm của tôi là dự đoán tầng cha trước, xong với mỗi  input+cha => để dự đoán con 

Input Text 

    ↓

[TF-IDF Vectorization]

    ↓  

[Parent Classifier] → Parent Labels

    ↓

[Text Features + Parent Labels] 

    ↓

[Child Classifier] → Child Labels

    ↓

[Post-processing: Filter invalid parent-child combinations]

# 1. ...

 1.Approach của tôi: ```bash Science → Physics vs Science → Math  thì điểm: f1_macro_parent = 1, f1_macro_science = 0

{ 'f1_macro_parent': 0.85, 'f1_macro_per_parent': {...} }

{ 'f1_macro_parent': 0.85, 'f1_macro_per_parent': {"f1_macro_child1": "", ....} } 
```

{
    'f1_macro_parent': 0.85,
    'f1_macro_per_parent': {
        'Technology': 0.78,
        'Science': 0.82,
        'Arts': 0.45,
        'Business': 0.71
    },
    'f1_macro_children_overall': 0.69,
}


# 2. Hiclass 

2. HiClass tự động Mở rộng tổ tiên (Ancestor Expansion) 
```bash 
Prediction: Science → Physics 
=> Được mở rộng thành: ROOT → Science → Physics  
True: Science → Math 
=> Được mở rộng thành: ROOT → Science → Math  Intersection: {ROOT, Science} = 2/3 = 0.67 điểm 
```


Đây là 3 metrics khác nhau trong HiClass hierarchical evaluation. Tôi sẽ giải thích chi tiết:

## **Hierarchical Precision, Recall, F1 là gì?**

### **1. Hierarchical Precision**
```
hierarchical_precision = Số labels đúng trong prediction / Tổng số labels được predict
```

**Ý nghĩa:** Trong những gì model predict, có bao nhiều % là đúng?

### **2. Hierarchical Recall**  
```
hierarchical_recall = Số labels đúng trong prediction / Tổng số labels thật
```

**Ý nghĩa:** Trong những gì thật, model đã predict được bao nhiều %?

### **3. Hierarchical F1**
```
hierarchical_f1 = 2 * precision * recall / (precision + recall)
```

**Ý nghĩa:** Harmonic mean của precision và recall.

## **Concrete Example:**

```
True: Science → Math
Pred: Science → Physics

Sau ancestor expansion:
True expanded: {ROOT, ROOT→Science, ROOT→Science→Math} = 3 items
Pred expanded: {ROOT, ROOT→Science, ROOT→Science→Physics} = 3 items
Intersection: {ROOT, ROOT→Science} = 2 items
```

### **Tính toán:**

**Hierarchical Precision:**
```
= 2/3 = 0.667
= "Trong 3 things model predict, có 2 cái đúng"
```

**Hierarchical Recall:**
```  
= 2/3 = 0.667
= "Trong 3 things thật, model đã tìm được 2 cái"
```

**Hierarchical F1:**
```
= 2 * 0.667 * 0.667 / (0.667 + 0.667) = 0.667
```

## **Khi nào khác nhau?**

### **Case 1: Over-prediction (Precision < Recall)**
```
True: Science → Math
Pred: Science → Math + Technology → Programming

True expanded: {ROOT, ROOT→Science, ROOT→Science→Math} = 3
Pred expanded: {ROOT, ROOT→Science, ROOT→Science→Math, ROOT→Technology, ROOT→Technology→Programming} = 5
Intersection: {ROOT, ROOT→Science, ROOT→Science→Math} = 3

Precision = 3/5 = 0.600  (predict quá nhiều)
Recall = 3/3 = 1.000     (tìm được hết)
F1 = 0.750
```

### **Case 2: Under-prediction (Precision > Recall)**
```
True: Science → Math + Technology → Programming  
Pred: Science → Math

True expanded: 5 items
Pred expanded: 3 items
Intersection: 3 items

Precision = 3/3 = 1.000  (predict ít nhưng đúng hết)
Recall = 3/5 = 0.600     (miss một số labels)
F1 = 0.750
```

## **Interpretation trong context:**

### **Hierarchical Precision = 0.571**
- "Trong những paths model predict, 57.1% là đúng"
- Model có xu hướng over-predict (predict thêm labels không cần thiết)

### **Hierarchical Recall = 0.571**  
- "Model đã tìm được 57.1% paths thật"
- Model có xu hướng under-predict (miss một số labels cần thiết)

### **Hierarchical F1 = 0.571**
- Balanced score giữa precision và recall
- Score này thường được dùng làm primary metric

## **So với Your Approach:**

**Your Approach:** Binary scoring cho từng component
```
f1_macro_parent: 0.750     (parent level performance)
f1_macro_science: 0.333    (children level performance)
```

**HiClass:** Unified scoring cho toàn bộ hierarchy
```
hierarchical_f1: 0.571    (overall hierarchical performance)
```

## **Key Insight:**

Khi cả 3 metrics bằng nhau (0.571), nghĩa là:
- Model predict đúng tỷ lệ như nhau so với true và predicted sets
- Không có bias toward over-prediction hay under-prediction
- Balanced performance across hierarchy levels

Đây là case đặc biệt - thường precision và recall sẽ khác nhau tùy thuộc model behavior.